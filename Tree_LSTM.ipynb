{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tree_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kOHLzD3SEVtz",
        "pax-ncbxQg6L",
        "RjAjlnW0Iijg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Zddx3NIKh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc73142a-c221-4d8e-d758-8e32eee88ce9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niT1p344PP5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c40e251b-9fcf-464b-ca25-46189af74521"
      },
      "source": [
        "import json\n",
        "import glob2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer   \n",
        "from transformers import BertModel"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHq-fvZYRiA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Node():\n",
        "#   def __init__(self,x=None,y=None,id=None,node1=None,node2=None):\n",
        "#     global gb\n",
        "#     if(id is None and (node1 is None or node2 is None)):\n",
        "#       raise Exception(\"To create non virtual nodes, id is required\")\n",
        "#     if(id is not None):\n",
        "#       self.id=str(id)\n",
        "#       self.is_leaf_node=True\n",
        "#     else:\n",
        "#       gb.varint+=1\n",
        "#       self.id='vir_'+ str(gb.varint)\n",
        "#       self.node1=node1\n",
        "#       self.node2=node2  \n",
        "#       if('vir_' in node1.id and 'vir_' in node2.id):\n",
        "#         self.is_stance_node=False\n",
        "#       else:\n",
        "#         self.is_stance_node=True\n",
        "#       self.is_leaf_node=False  \n",
        "#     self.x=x\n",
        "#     self.y=y\n",
        "#     self.c=None\n",
        "#     self.h=None \n",
        "class Node():\n",
        "  def __init__(self,x=None,y=None,id=None,children=None):\n",
        "     self.x=x\n",
        "     self.id=id\n",
        "     self.y=y\n",
        "     self.children=children\n",
        "     self.h=None\n",
        "     self.c=None    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLnrQE-THLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Global:\n",
        "    def __init__(self):\n",
        "      # self.varint=0\n",
        "      # self.g_parent=None\n",
        "      self.g_nodes=[] \n",
        "    def reset(self):\n",
        "      # self.varint=0\n",
        "      # self.g_parent=None\n",
        "      self.g_nodes=[]\n",
        "\n",
        "def get_key_value(dicts,search_id,keys=None):\n",
        "  res={}\n",
        "  for d in dicts:\n",
        "    if('id' in d.keys()):\n",
        "      if(str(d['id'])==str(search_id)):\n",
        "        for k in keys:\n",
        "          res[k]=d[k]\n",
        "        break\n",
        "    else:\n",
        "      if(search_id in d.keys()):  \n",
        "        return d[search_id]\n",
        "      else:\n",
        "        return None        \n",
        "  return list(res.values()) \n",
        "\n",
        "def uniform_embed(size):\n",
        "  return np.random.uniform(low=-0.5, high=0.5, size=(size))\n",
        "\n",
        "def create_tree(tree,tweets=None,stance_dict=None,parent=None,embed_size=2400):\n",
        "  global gb\n",
        "  children=[]\n",
        "  for key,value in tree.items():\n",
        "    if(type(value)==dict):      \n",
        "      child=create_tree(value,tweets,stance_dict,parent=key,embed_size=embed_size)\n",
        "      embed=get_key_value(dicts=tweets,search_id=key,keys=['text'])\n",
        "      if(len(embed)>0 and len(embed[0])>0):\n",
        "        embed=embed[0]\n",
        "      else:\n",
        "        embed=uniform_embed(embed_size)       \n",
        "      parent_node=Node(id=key,x=embed,children=child)\n",
        "      children.append(parent_node)\n",
        "      gb.g_nodes.append(parent_node)\n",
        "    else:\n",
        "      embed=get_key_value(dicts=tweets,search_id=key,keys=['text'])\n",
        "      if(len(embed)>0 and len(embed[0])>0):\n",
        "        embed=embed[0]\n",
        "      else:\n",
        "        embed=uniform_embed(embed_size)            \n",
        "      child=Node(id=key,x=embed)\n",
        "      children.append(child)\n",
        "      gb.g_nodes.append(child) \n",
        "  return children    \n",
        "  #   children.append(child) \n",
        "  # if(gb.g_parent is not None):\n",
        "  #   arr=[gb.g_parent]\n",
        "  #   arr.extend(children)\n",
        "  #   children=arr \n",
        "  # if(parent is not None):\n",
        "  #   nodes=[]\n",
        "  #   for child in children:\n",
        "  #     if('vir_' not in str(parent) and 'vir_' in child.id):\n",
        "  #       nodes.append(child)\n",
        "  #       continue\n",
        "  #     embed=get_key_value(dicts=tweets,search_id=parent,keys=['text']) \n",
        "  #     if(len(embed)>0 and len(embed[0])>0):\n",
        "  #       embed=embed[0]  \n",
        "  #     else:\n",
        "  #       embed=uniform_embed(embed_size)      \n",
        "  #     parent_node=Node(id=parent,x=embed) \n",
        "  #     stance=None\n",
        "  #     if('var_' not in parent_node.id and 'var_' not in child.id):\n",
        "  #       stance=get_key_value(dicts=[stance_dict],search_id=child.id) \n",
        "  #     node=Node(node1=parent_node,node2=child,y=stance)\n",
        "  #     # print(parent,child.id,node.id)\n",
        "  #     gb.g_nodes.extend([parent_node,child,node])\n",
        "  #     nodes.append(node)\n",
        "  #   node1=nodes[0] \n",
        "  #   for node_iter in range(1,len(nodes)):\n",
        "  #     node2=nodes[node_iter]\n",
        "  #     node=Node(node1=node1,node2=node2)\n",
        "  #     # print(node1.id,node2.id,node.id)\n",
        "  #     gb.g_nodes.extend([node])\n",
        "  #     node1=node \n",
        "  #   embed=get_key_value(dicts=tweets,search_id=parent,keys=['text']) \n",
        "  #   if(len(embed)>0 and len(embed[0])>0):\n",
        "  #     embed=embed[0]  \n",
        "  #   else:\n",
        "  #     embed=uniform_embed(embed_size)            \n",
        "  #   gb.g_parent=Node(id=parent,x=embed)\n",
        "  #   return node1\n",
        "  # return children     "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOHLzD3SEVtz",
        "colab_type": "text"
      },
      "source": [
        "# SKP Encoder python2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV-_CED6upUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f00f1f7b-adff-4294-94c1-bd6fa48014d5"
      },
      "source": [
        "# !git clone https://github.com/ryankiros/skip-thoughts.git\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/dictionary.txt -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/utable.npy -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/btable.npy -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz -P skip-thoughts\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl -P skip-thoughts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 03:49:17--  http://www.cs.toronto.edu/~rkiros/models/dictionary.txt\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7996547 (7.6M) [text/plain]\n",
            "Saving to: ‘skip-thoughts/dictionary.txt’\n",
            "\n",
            "dictionary.txt      100%[===================>]   7.63M  11.0MB/s    in 0.7s    \n",
            "\n",
            "2020-06-21 03:49:17 (11.0 MB/s) - ‘skip-thoughts/dictionary.txt’ saved [7996547/7996547]\n",
            "\n",
            "--2020-06-21 03:49:19--  http://www.cs.toronto.edu/~rkiros/models/utable.npy\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2342138474 (2.2G)\n",
            "Saving to: ‘skip-thoughts/utable.npy’\n",
            "\n",
            "utable.npy          100%[===================>]   2.18G  84.4MB/s    in 28s     \n",
            "\n",
            "2020-06-21 03:49:47 (79.0 MB/s) - ‘skip-thoughts/utable.npy’ saved [2342138474/2342138474]\n",
            "\n",
            "--2020-06-21 03:49:49--  http://www.cs.toronto.edu/~rkiros/models/btable.npy\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2342138474 (2.2G)\n",
            "Saving to: ‘skip-thoughts/btable.npy’\n",
            "\n",
            "btable.npy          100%[===================>]   2.18G  33.6MB/s    in 31s     \n",
            "\n",
            "2020-06-21 03:50:20 (71.1 MB/s) - ‘skip-thoughts/btable.npy’ saved [2342138474/2342138474]\n",
            "\n",
            "--2020-06-21 03:50:22--  http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 663989216 (633M)\n",
            "Saving to: ‘skip-thoughts/uni_skip.npz’\n",
            "\n",
            "uni_skip.npz        100%[===================>] 633.23M  77.9MB/s    in 8.3s    \n",
            "\n",
            "2020-06-21 03:50:30 (76.5 MB/s) - ‘skip-thoughts/uni_skip.npz’ saved [663989216/663989216]\n",
            "\n",
            "--2020-06-21 03:50:31--  http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 693\n",
            "Saving to: ‘skip-thoughts/uni_skip.npz.pkl’\n",
            "\n",
            "uni_skip.npz.pkl    100%[===================>]     693  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-21 03:50:32 (90.3 MB/s) - ‘skip-thoughts/uni_skip.npz.pkl’ saved [693/693]\n",
            "\n",
            "--2020-06-21 03:50:34--  http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 289340074 (276M)\n",
            "Saving to: ‘skip-thoughts/bi_skip.npz’\n",
            "\n",
            "bi_skip.npz         100%[===================>] 275.94M  70.2MB/s    in 4.1s    \n",
            "\n",
            "2020-06-21 03:50:38 (66.5 MB/s) - ‘skip-thoughts/bi_skip.npz’ saved [289340074/289340074]\n",
            "\n",
            "--2020-06-21 03:50:40--  http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 689\n",
            "Saving to: ‘skip-thoughts/bi_skip.npz.pkl’\n",
            "\n",
            "bi_skip.npz.pkl     100%[===================>]     689  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-21 03:50:40 (105 MB/s) - ‘skip-thoughts/bi_skip.npz.pkl’ saved [689/689]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlS81VnUzY_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cee25d3d-5fbd-4aa4-ed99-3d375f98907a"
      },
      "source": [
        "# %cd skip-thoughts\n",
        "# import importlib\n",
        "# importlib.reload(skipthoughts)\n",
        "import skipthoughts\n",
        "model = skipthoughts.load_model()\n",
        "encoder = skipthoughts.Encoder(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'skip-thoughts'\n",
            "/content/skip-thoughts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pax-ncbxQg6L",
        "colab_type": "text"
      },
      "source": [
        "# SKP encoder python3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y78n9GkwQlW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "516ddb79-ffc2-42df-99eb-3a53f340fac2"
      },
      "source": [
        "!wget \"http://download.tensorflow.org/models/skip_thoughts_bi_2017_02_16.tar.gz\"\n",
        "!tar -xvf skip_thoughts_bi_2017_02_16.tar.gz\n",
        "!rm skip_thoughts_bi_2017_02_16.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 06:02:01--  http://download.tensorflow.org/models/skip_thoughts_bi_2017_02_16.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.214.128, 2607:f8b0:400c:c0b::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.214.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5680270817 (5.3G) [application/x-gzip]\n",
            "Saving to: ‘skip_thoughts_bi_2017_02_16.tar.gz’\n",
            "\n",
            "skip_thoughts_bi_20 100%[===================>]   5.29G  58.6MB/s    in 74s     \n",
            "\n",
            "2020-06-21 06:03:15 (72.9 MB/s) - ‘skip_thoughts_bi_2017_02_16.tar.gz’ saved [5680270817/5680270817]\n",
            "\n",
            "skip_thoughts_bi_2017_02_16/\n",
            "skip_thoughts_bi_2017_02_16/model.ckpt-500008.data-00000-of-00001\n",
            "skip_thoughts_bi_2017_02_16/vocab.txt\n",
            "skip_thoughts_bi_2017_02_16/model.ckpt-500008.index\n",
            "skip_thoughts_bi_2017_02_16/embeddings.npy\n",
            "skip_thoughts_bi_2017_02_16/model.ckpt-500008.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaMrmVASYMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "39dc2b9d-037e-40db-f5e0-7bdbc4b943aa"
      },
      "source": [
        "!git clone https://github.com/elvisyjlin/skip-thoughts.git\n",
        "%tensorflow_version 1.x\n",
        "%cd skip-thoughts/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'skip-thoughts'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "Unpacking objects:   2% (1/35)   \rUnpacking objects:   5% (2/35)   \rUnpacking objects:   8% (3/35)   \rUnpacking objects:  11% (4/35)   \rUnpacking objects:  14% (5/35)   \rUnpacking objects:  17% (6/35)   \rUnpacking objects:  20% (7/35)   \rUnpacking objects:  22% (8/35)   \rUnpacking objects:  25% (9/35)   \rUnpacking objects:  28% (10/35)   \rUnpacking objects:  31% (11/35)   \rUnpacking objects:  34% (12/35)   \rUnpacking objects:  37% (13/35)   \rUnpacking objects:  40% (14/35)   \rUnpacking objects:  42% (15/35)   \rUnpacking objects:  45% (16/35)   \rUnpacking objects:  48% (17/35)   \rUnpacking objects:  51% (18/35)   \rremote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35\u001b[K\n",
            "Unpacking objects:  54% (19/35)   \rUnpacking objects:  57% (20/35)   \rUnpacking objects:  60% (21/35)   \rUnpacking objects:  62% (22/35)   \rUnpacking objects:  65% (23/35)   \rUnpacking objects:  68% (24/35)   \rUnpacking objects:  71% (25/35)   \rUnpacking objects:  74% (26/35)   \rUnpacking objects:  77% (27/35)   \rUnpacking objects:  80% (28/35)   \rUnpacking objects:  82% (29/35)   \rUnpacking objects:  85% (30/35)   \rUnpacking objects:  88% (31/35)   \rUnpacking objects:  91% (32/35)   \rUnpacking objects:  94% (33/35)   \rUnpacking objects:  97% (34/35)   \rUnpacking objects: 100% (35/35)   \rUnpacking objects: 100% (35/35), done.\n",
            "TensorFlow 1.x selected.\n",
            "/content/skip-thoughts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dM1OqcURRRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "9f0da27e-3a3d-42ed-d827-594f7a402d34"
      },
      "source": [
        "from skip_thoughts import configuration\n",
        "from skip_thoughts import encoder_manager\n",
        "\n",
        "VOCAB_FILE = \"skip_thoughts_bi_2017_02_16/vocab.txt\"\n",
        "EMBEDDING_MATRIX_FILE = \"skip_thoughts_bi_2017_02_16/embeddings.npy\"\n",
        "CHECKPOINT_PATH = \"skip_thoughts_bi_2017_02_16/model.ckpt-500008\"\n",
        "\n",
        "encoder = encoder_manager.EncoderManager()\n",
        "encoder.load_model(configuration.model_config(bidirectional_encoder=True),\n",
        "                   vocabulary_file=VOCAB_FILE,\n",
        "                   embedding_matrix_file=EMBEDDING_MATRIX_FILE,\n",
        "                   checkpoint_path=CHECKPOINT_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/encoder_manager.py:63: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Reading vocabulary from skip_thoughts_bi_2017_02_16/vocab.txt\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/encoder_manager.py:64: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Loaded vocabulary with 930914 words.\n",
            "INFO:tensorflow:Loading embedding matrix from skip_thoughts_bi_2017_02_16/embeddings.npy\n",
            "INFO:tensorflow:Loaded embedding matrix with shape (930914, 620)\n",
            "INFO:tensorflow:Building model.\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:71: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:127: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:230: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:231: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:246: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/ops/gru_cell.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:47: The name tf.svd is deprecated. Please use tf.linalg.svd instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:47: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_model.py:360: The name tf.train.create_global_step is deprecated. Please use tf.compat.v1.train.create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_encoder.py:151: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/skip_thoughts_encoder.py:122: The name tf.gfile.IsDirectory is deprecated. Please use tf.io.gfile.isdir instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/encoder_manager.py:85: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/skip-thoughts/skip_thoughts/encoder_manager.py:87: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "INFO:tensorflow:Loading model from checkpoint: skip_thoughts_bi_2017_02_16/model.ckpt-500008\n",
            "INFO:tensorflow:Restoring parameters from skip_thoughts_bi_2017_02_16/model.ckpt-500008\n",
            "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-500008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjAjlnW0Iijg",
        "colab_type": "text"
      },
      "source": [
        "# DeepMoji Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z59XYZIqauxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "7a3c4aa4-4d04-42da-86dd-7370d8686d2e"
      },
      "source": [
        "# for deepMoji\n",
        "!git clone https://github.com/zzsza/DeepMoji-Python3.git\n",
        "%cd DeepMoji-Python3/DeepMoji-master\n",
        "!python scripts/download_weights.py\n",
        "!pip install emoji\n",
        "# replace downloaded encode_texts.py file with modified file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepMoji-Python3'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Total 85 (delta 0), reused 0 (delta 0), pack-reused 85\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n",
            "/content/DeepMoji-Python3/DeepMoji-master\n",
            "About to download the pretrained weights file from https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0#\n",
            "The size of the file is roughly 85MB. Continue? [y/n]\n",
            "y\n",
            "Downloading...\n",
            "Running system call: wget https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0# -O /content/DeepMoji-Python3/DeepMoji-master/model/deepmoji_weights.hdf5\n",
            "--2020-06-22 07:25:53--  https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.67.1, 2620:100:6023:1::a27d:4301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.67.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/xqarafsl6a8f9ny/deepmoji_weights.hdf5 [following]\n",
            "--2020-06-22 07:25:53--  https://www.dropbox.com/s/raw/xqarafsl6a8f9ny/deepmoji_weights.hdf5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com/cd/0/inline/A6E8CZ7Elc2iI4VS2Kbt3APmP-kFYxQSA2zc9e5A5wnrKheWKduSoIvRLbaymId_nDlnqAwVq-rWB3QqqG7OG_SYczSBQCW2YL1LlsbtJ2jJ4Q/file# [following]\n",
            "--2020-06-22 07:25:54--  https://ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com/cd/0/inline/A6E8CZ7Elc2iI4VS2Kbt3APmP-kFYxQSA2zc9e5A5wnrKheWKduSoIvRLbaymId_nDlnqAwVq-rWB3QqqG7OG_SYczSBQCW2YL1LlsbtJ2jJ4Q/file\n",
            "Resolving ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com (ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6023:15::a27d:430f\n",
            "Connecting to ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com (ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/A6EQ5qadDs7AjIpzfoLtMUeRY9tPqaJ7gXzemmUYcn5NOAeaq5V2CT9mL7vnVvnr6PlKuAqWIIgIj3YDWlVYZhR9PvTWJ7yBUDx-p22jNz-VwguISE3XC8hesXIvUkeoiGma0f2L-NrE5ZlazCp_w4lf3xL7BHMlIA9Il0aG0cLLF-QyY-570TBOg0maefVDs5I1Nmpd7-D0kc4W40DrMGDCb81Pxo6N5J9WqY7zWZJLbF-yTtJb-rAT7Eeyxr0rmXT63FOEd4Usml-gwu79pa1nZhw6IdRm0Uy82elz1ccB91KdEhGWMoEgMenUINH0g4P8_U2mlyrTrUurBAnYgbKc/file [following]\n",
            "--2020-06-22 07:25:55--  https://ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com/cd/0/inline2/A6EQ5qadDs7AjIpzfoLtMUeRY9tPqaJ7gXzemmUYcn5NOAeaq5V2CT9mL7vnVvnr6PlKuAqWIIgIj3YDWlVYZhR9PvTWJ7yBUDx-p22jNz-VwguISE3XC8hesXIvUkeoiGma0f2L-NrE5ZlazCp_w4lf3xL7BHMlIA9Il0aG0cLLF-QyY-570TBOg0maefVDs5I1Nmpd7-D0kc4W40DrMGDCb81Pxo6N5J9WqY7zWZJLbF-yTtJb-rAT7Eeyxr0rmXT63FOEd4Usml-gwu79pa1nZhw6IdRm0Uy82elz1ccB91KdEhGWMoEgMenUINH0g4P8_U2mlyrTrUurBAnYgbKc/file\n",
            "Reusing existing connection to ucf60450f87130cd2deb6575e0a8.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89610904 (85M) [application/octet-stream]\n",
            "Saving to: ‘/content/DeepMoji-Python3/DeepMoji-master/model/deepmoji_weights.hdf5’\n",
            "\n",
            "/content/DeepMoji-P 100%[===================>]  85.46M  25.5MB/s    in 3.4s    \n",
            "\n",
            "2020-06-22 07:25:59 (25.5 MB/s) - ‘/content/DeepMoji-Python3/DeepMoji-master/model/deepmoji_weights.hdf5’ saved [89610904/89610904]\n",
            "\n",
            "Downloaded weights to model/deepmoji_weights.hdf5\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=196862db73a3c5421d0592e81bdf1793d55d3c33aceca293938d27076f9fc86a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB-T5Kc8UrH3",
        "colab_type": "text"
      },
      "source": [
        "# BERT Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFHWKvsUlet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(SentenceClassifier, self).__init__()\n",
        "      self.bert_layer = BertModel.from_pretrained('/content/drive/My Drive/BERT_CONFIG')\n",
        "      self.linear = nn.Linear(768*2, 3)\n",
        "      self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self,seq,mask):\n",
        "      _,cls = self.bert_layer(seq, attention_mask = mask)\n",
        "      return cls"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtCTCPODEdKd",
        "colab_type": "text"
      },
      "source": [
        "# Encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So06O3J_cKNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import examples.encode_texts\n",
        "\n",
        "class GLOVE:\n",
        "  def __init__(self,embedding_file):\n",
        "    self.vocab={}\n",
        "    self.unk=[0 for i in range(300)]\n",
        "    with open(embedding_file, 'rt', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        splitline=line.split()\n",
        "        self.vocab[splitline[0]]=[float(value) for value in splitline[1:]]\n",
        "    self.size=300    \n",
        "  def embed(self,tokens):\n",
        "    embed = [self.vocab.get(token,self.unk) for token in tokens]\n",
        "    embed = [sum(x)/len(x) for x in zip(*embed)]\n",
        "    return embed\n",
        "\n",
        "class DeepMoji:\n",
        "  def __init__(self):\n",
        "    self.size=2304\n",
        "  def embed(self,tokens):\n",
        "    embed=examples.encode_texts.encode(np.array([''.join(tokens)]))\n",
        "    return embed.reshape(2304)\n",
        "\n",
        "class SKP:\n",
        "  def __init__(self,encoder):\n",
        "    self.encoder=encoder\n",
        "    self.size=2400\n",
        "  def embed(self,tokens):\n",
        "    embed=self.encoder.encode(tokens) \n",
        "    embed=[sum(x)/len(x) for x in zip(*embed)]\n",
        "    return embed\n",
        "\n",
        "class skpemt:\n",
        "  def __init__(self,encoder):\n",
        "    self.encoder=encoder\n",
        "    self.size=2400+2304\n",
        "  def embed(self,tokens):\n",
        "    encoding=self.encoder.encode(tokens) \n",
        "    encoding=[sum(x)/len(x) for x in zip(*encoding)]\n",
        "    deepmoji_encoding=examples.encode_texts.encode(np.array([''.join(tokens)]))\n",
        "    deepmoji_encoding= list(deepmoji_encoding.reshape(2304))\n",
        "    encoding.extend(deepmoji_encoding)\n",
        "    return encoding \n",
        "\n",
        "class BERT:\n",
        "  def __init__(self):\n",
        "    self.model=SentenceClassifier()\n",
        "    self.model.load_state_dict(torch.load('/content/drive/My Drive/BERT_CONFIG/multinli_model.pt'))\n",
        "    self.size=768\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/BERT_CONFIG')    \n",
        "  def tokenize(self,tokens):\n",
        "    return [self.tokenizer.convert_tokens_to_ids('[CLS]')]\\\n",
        "      +[self.tokenizer.convert_tokens_to_ids(tok) for tok in tokens]\n",
        "  def embed(self,tokens):\n",
        "    tokenized=torch.tensor(self.tokenize(tokens)).view(1,-1)\n",
        "    mask=torch.tensor([1 for i in range(tokenized.size(-1))]).view(1,-1)\n",
        "    return self.model(tokenized,mask)            "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A71C2kpIDq7R",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ShAG5hdwiEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_datapoint(source,reply_list,struct,stance_dict,embedding):\n",
        "    tweets=reply_list+[source]\n",
        "    create_tree(struct,tweets,stance_dict,embed_size=embedding.size)\n",
        "\n",
        "def preprocess(tweet):\n",
        "    # remove @mentions, RT,MT,DM,PRT,HT,CC, URLs\n",
        "    contractions = { \n",
        "      \"n't\": \"not\",\n",
        "      \"'ve\": \"have\",\n",
        "      \"'d\": \"would\",\n",
        "      \"'ll\": \"will\",\n",
        "      \"'m\": \"am\",\n",
        "      \"ma'am\": \"madam\",\n",
        "      \"'re\": \"they are\"\n",
        "      }\n",
        "    text=tweet.lower()  \n",
        "    tokens=text.split()\n",
        "    # print(tokens)\n",
        "    for indx,token in enumerate(tokens):\n",
        "        for contra in contractions.keys():\n",
        "            if(contra in token):\n",
        "                tokens[indx]=' '.join([token.replace(contra,''),contractions[contra]])\n",
        "    text=' '.join(tokens)\n",
        "    # Format words and remove unwanted characters    \n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'([@?])(\\w+)\\b', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    text=text.replace('mt ',' ').replace('rt ',' ').replace('dm ',' ').replace('prt ',' ').replace('ht ',' ').replace('cc ',' ')\n",
        "    tokens = text.split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    tokens = [w for w in tokens if not w in stops]\n",
        "    return tokens"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFONag3ECPeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c7dd13b6-0252-47e3-b5eb-2be4f7a5c7f9"
      },
      "source": [
        "text='MT @euronews France: 10 dead after shooting at HQ of satirical weekly #CharlieHebdo. If Zionists/Jews did this they\\'d be nuking Israel'\n",
        "preprocess(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['france',\n",
              " '10',\n",
              " 'dead',\n",
              " 'shooting',\n",
              " 'hq',\n",
              " 'satirical',\n",
              " 'weekly',\n",
              " 'charliehebdo',\n",
              " 'zionists',\n",
              " 'jews',\n",
              " 'would',\n",
              " 'nuking',\n",
              " 'israel']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGCXrpnADywP",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GON9ei_6nZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TreeLSTMCell(nn.Module):\n",
        "  def __init__(self,x_size,h_size):\n",
        "    super(TreeLSTMCell, self).__init__()\n",
        "    self.W_iou = nn.Linear(x_size, 3 * h_size, bias=False)\n",
        "    self.U_iou = nn.Linear(h_size, 3 * h_size, bias=False)\n",
        "    self.b_iou = nn.Parameter(torch.zeros(1, 3 * h_size))\n",
        "    self.U_f = nn.Linear(h_size, h_size)\n",
        "    self.b_f = nn.Parameter(torch.zeros(1, h_size))      \n",
        "    self.h=torch.zeros(1,h_size)\n",
        "    self.c=torch.zeros(1,h_size)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.conv=nn.Conv1d(in_channels=1,out_channels=1, kernel_size=2, stride=1,padding=1)\n",
        "    self.maxpool=nn.AdaptiveMaxPool1d(768)\n",
        "    self.stance_linear=nn.Linear(h_size,4)\n",
        "    self.veracity_linear=nn.Linear(h_size,3)\n",
        "    self.softmax=nn.Softmax()\n",
        "    self.h_size=h_size\n",
        "  def reset_h_c(self):\n",
        "    self.h=torch.zeros(1,self.h_size)\n",
        "    self.c=torch.zeros(1,self.h_size)    \n",
        "  def forward(self,node,is_last=False):      \n",
        "    if(node.children is None):\n",
        "      x=torch.tensor(node.x,dtype=torch.float)\n",
        "      x_iou=self.W_iou(x) \n",
        "      u_iou=self.U_iou(self.h)\n",
        "      b_iou=self.b_iou      \n",
        "      xs=torch.chunk(x_iou,3,-1)\n",
        "      us=torch.chunk(u_iou,3,-1)\n",
        "      bs=torch.chunk(b_iou,3,-1)       \n",
        "      i=self.sigmoid(xs[0]+us[0]+bs[0])\n",
        "      o=self.sigmoid(xs[1]+us[1]+bs[1])\n",
        "      u=self.sigmoid(xs[2]+us[2]+bs[2])\n",
        "      self.c=i*u\n",
        "      self.h=o*self.tanh(self.c)\n",
        "      node.h=self.h\n",
        "      node.c=self.c\n",
        "    else:\n",
        "      h_stack=torch.stack([child.h for child in node.children])\n",
        "      u_f=self.U_f(h_stack.view(-1,self.h_size))\n",
        "      f=self.sigmoid(u_f+self.b_f)\n",
        "      # print(h_stack.shape)\n",
        "      h_hat,_=torch.max(self.maxpool(self.conv(h_stack)),dim=0,keepdim=True)\n",
        "      u_iou=self.U_iou(h_hat.view(1,-1))\n",
        "\n",
        "      us=torch.chunk(u_iou,3,-1)\n",
        "      bs=torch.chunk(self.b_iou,3,-1)            \n",
        "      i=self.sigmoid(us[0]+bs[0])\n",
        "      o=self.sigmoid(us[1]+bs[1])\n",
        "      u=self.sigmoid(us[2]+bs[2])\n",
        "      self.c=i*u + torch.sum(f.view(-1,self.h_size)*torch.stack([child.c for child in node.children]).view(-1,self.h_size),0)\n",
        "      self.h=o*self.tanh(self.c)\n",
        "      node.h=self.h\n",
        "      node.c=self.c\n",
        "      if(is_last):\n",
        "        veracity=self.softmax(self.veracity_linear(self.h))\n",
        "        print('veracity:{}'.format(veracity))\n",
        "        return veracity \n",
        "      stance=self.softmax(self.stance_linear(self.h))\n",
        "      return stance          "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BUz6Z-D9Im",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCge3WdLxGVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "veracity_enum = { \n",
        "  'true':0,\n",
        "  'false':1,\n",
        "  'unverified':2\n",
        "}\n",
        "\n",
        "stance_enum={\n",
        "    'support':0,\n",
        "    'comment':1,\n",
        "    'query':2,\n",
        "    'deny':3\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtpE3flOxJjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Event:\n",
        "  def __init__(self,path):\n",
        "    self.path=path\n",
        "    self.treelist=[]\n",
        "  def create_tree(self,gb):\n",
        "    dirs=os.listdir(self.path)\n",
        "    for d in dirs:\n",
        "      if(d=='.DS_Store'):\n",
        "        continue\n",
        "      source=glob2.glob(self.path+'/'+ d + '/source-tweet/*.json')[0]\n",
        "      replies=glob2.glob(self.path+'/'+ d + '/replies/*.json')\n",
        "      structure=self.path+'/'+ d + '/structure.json'\n",
        "      gb.reset()\n",
        "      reply_list=[]\n",
        "      with open(source,'r') as f:\n",
        "        source=json.load(f,parse_int=None)\n",
        "      processed_text= preprocess(source['text'])  \n",
        "      if(len(processed_text)>0):  \n",
        "        source={'id':source['id'],'text':embedding.embed(processed_text)}  \n",
        "      else:\n",
        "        source={'id':source['id'],'text':processed_text}        \n",
        "      for reply in replies:\n",
        "        with open(reply,'r') as f:\n",
        "          reply=json.load(f,parse_int=None)\n",
        "        processed_text= preprocess(reply['text'])\n",
        "        if(len(processed_text)>0):\n",
        "          reply={'id':reply['id'],'text':embedding.embed(processed_text)}\n",
        "        else:\n",
        "          reply={'id':reply['id'],'text':processed_text} \n",
        "        reply_list.append(reply)\n",
        "        # print(reply_list)      \n",
        "      with open(structure,'r') as f:\n",
        "        struct=json.load(f,parse_int=None)\n",
        "      create_datapoint(source,reply_list,struct,stance_dict,embedding=embedding)\n",
        "      self.treelist.append((source['id'],gb.g_nodes))      "
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyYAVCeTxP-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load stance labels\n",
        "rumour_files=glob2.glob('/content/drive/My Drive/rumoureval-data/traindev/*subtaskA*.json')\n",
        "stance_dict={}\n",
        "for file in rumour_files:\n",
        "  with open(file,'r') as f:\n",
        "    stance_dict.update(json.load(f,parse_int=None))\n",
        "for k,v in stance_dict.items():\n",
        "  stance_dict[k]=stance_enum[v]\n",
        "\n",
        "#load veracity labels\n",
        "rumour_files=glob2.glob('/content/drive/My Drive/rumoureval-data/traindev/*subtaskB*.json')\n",
        "veracity_dict={}\n",
        "for file in rumour_files:\n",
        "  with open(file,'r') as f:\n",
        "    veracity_dict.update(json.load(f,parse_int=None))\n",
        "for k,v in veracity_dict.items():\n",
        "  veracity_dict[k]=veracity_enum[v]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6MfputFM0Ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f2e40d4-b004-42ed-e3a6-d72ea0a6cd1d"
      },
      "source": [
        "embedding=BERT()\n",
        "with open('/content/drive/My Drive/rumoureval-data/charliehebdo/553184482241814530/replies/553184702530453505.json','r') as f:\n",
        "  source=json.load(f,parse_int=None)\n",
        "source={'id':source['id'],'text':embedding.embed(preprocess(source['text']))} \n",
        "source\n",
        "# type(encoder.encode(['maybe', 'they', 'want', 'to', 'get' ,'caught']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
            "  category=FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 553184702530453505,\n",
              " 'text': tensor([[-0.3701, -0.2217,  0.9532,  0.5189,  0.8301,  0.2629,  0.8415,  0.6777,\n",
              "           0.9937, -0.9796,  0.9742, -0.8071,  0.9026, -0.2117,  0.9733, -0.5808,\n",
              "           0.0143, -0.3522,  0.3882, -0.8300,  0.7825,  0.0173,  0.8494,  0.6325,\n",
              "           0.3077, -0.8371, -0.4423,  0.9895,  0.9898,  0.4993, -0.1705, -0.5002,\n",
              "          -0.8806,  0.4054,  0.8998, -0.1324, -0.6142, -0.3484, -0.4314,  0.5374,\n",
              "          -0.9941,  0.6816,  0.7429, -0.9557,  0.6775,  0.0691, -0.0355, -0.3049,\n",
              "          -0.6994, -0.9876, -0.4933, -0.8455, -0.5568,  0.0603, -0.3631, -0.1101,\n",
              "          -0.6004, -0.7368, -0.5735,  0.1829,  0.0956, -0.5329,  0.7888, -0.8245,\n",
              "          -0.9179, -0.9017, -0.1838, -0.5882, -0.3484, -0.6698,  0.4890, -0.0192,\n",
              "           0.2107, -0.9385, -0.8362, -0.6202, -0.2919,  0.2919,  0.1369, -0.9912,\n",
              "          -0.9393, -0.8425, -0.2211,  0.8951, -0.6955,  0.0378, -0.8312,  0.2405,\n",
              "          -0.9967,  0.0448,  0.6354,  0.3575, -0.5427,  0.5747,  0.6675, -0.1693,\n",
              "           0.0197,  0.5401, -0.4984,  0.1811,  0.1552, -0.5009, -0.1438,  0.1869,\n",
              "           0.6898, -0.2626, -0.1717,  0.2362, -0.0249, -0.1254,  0.0480, -0.4671,\n",
              "          -0.1886, -0.7974, -0.4206,  0.5028, -0.9134,  0.3423, -0.9877,  0.0727,\n",
              "          -0.0406, -0.6431,  0.9892,  0.7438, -0.4995, -0.1511,  0.9927, -0.8214,\n",
              "           0.8687, -0.0556, -0.2533,  0.6068, -0.9716, -0.9809,  0.0788,  0.9862,\n",
              "          -0.3816,  0.8257, -0.3494,  0.9726,  0.8980,  0.9339, -0.8401,  0.2302,\n",
              "          -0.3241,  0.6796, -0.4616, -0.3014, -0.4131, -0.5775, -0.1803,  0.4278,\n",
              "           0.5129, -0.6538, -0.2762,  0.9907,  0.8497,  0.8123,  0.9724,  0.0573,\n",
              "          -0.6128,  0.7275, -0.0093,  0.5444, -0.5326,  0.1199, -0.4755, -0.5354,\n",
              "          -0.8735,  0.4846, -0.6161,  0.4237,  0.9326, -0.9949,  0.1759, -0.0439,\n",
              "           0.9921,  0.4536,  0.3807, -0.9298,  0.2727, -0.6183, -0.9875,  0.9714,\n",
              "          -0.4142, -0.5929, -0.6860, -0.1327, -0.9855, -0.0360, -0.2293,  0.5054,\n",
              "          -0.9814, -0.1369, -0.7137,  0.4390, -0.0664,  0.4965,  0.2441,  0.4117,\n",
              "           0.0263,  0.9980,  0.8206,  0.9027, -0.6468, -0.3879, -0.8211, -0.6490,\n",
              "          -0.5713,  0.3311,  0.1516,  0.9896, -0.6979, -0.2119, -0.9383, -0.9906,\n",
              "          -0.2072, -0.9760, -0.5267,  0.0889, -0.1775, -0.7618, -0.8560, -0.0200,\n",
              "          -0.1203, -0.9134, -0.2460,  0.4373, -0.0912,  0.5182,  0.9027, -0.9796,\n",
              "          -0.7560,  0.1069,  0.9924,  0.7499, -0.7314,  0.8372,  0.1689,  0.5415,\n",
              "           0.6279,  0.8091, -0.6898, -0.7976, -0.9352,  0.8243, -0.3257,  0.9765,\n",
              "          -0.4589, -0.2390, -0.9914,  0.4131, -0.0486, -0.0667,  0.1900,  0.8301,\n",
              "          -0.9526, -0.9405, -0.9887,  0.7565, -0.9364, -0.8312, -0.3670,  0.1302,\n",
              "           0.1288,  0.0215, -0.9761,  0.8076, -0.3667,  0.8099, -0.8587,  0.0078,\n",
              "           0.8507, -0.9257, -0.4570, -0.4075,  0.9811, -0.1859, -0.9840,  0.3718,\n",
              "           0.6772,  0.6323,  0.8710,  0.1266,  0.6995,  0.9837,  0.9746, -0.3238,\n",
              "          -0.8425, -0.9805,  0.6209,  0.9793, -0.8974, -0.9386,  0.1354,  0.6677,\n",
              "          -0.7241, -0.7617,  0.1522, -0.8346, -0.9238,  0.9805,  0.9027, -0.4903,\n",
              "           0.9349,  0.9880,  0.5876, -0.9627, -0.3602,  0.7517, -0.1278,  0.6921,\n",
              "           0.1705, -0.0695,  0.8653, -0.6224,  0.9374,  0.4449, -0.0585, -0.4620,\n",
              "          -0.4764, -0.9683, -0.2873,  0.3873, -0.2449, -0.9777, -0.7162, -0.9792,\n",
              "           0.6431,  0.4720,  0.2945, -0.6793, -0.5873, -0.1299,  0.6167, -0.4566,\n",
              "          -0.3041,  0.0363,  0.7422, -0.9396,  0.8561, -0.9899,  0.9023, -0.4112,\n",
              "          -0.9962,  0.5795,  0.6884, -0.9793,  0.4698, -0.5168, -0.0734,  0.6111,\n",
              "          -0.6633, -0.9679,  0.5234,  0.1859,  0.3249,  0.1661,  0.9835,  0.0342,\n",
              "           0.8739,  0.8578,  0.9827, -0.9801, -0.6531, -0.2214, -0.9867,  0.9783,\n",
              "           0.9396,  0.6129, -0.9482, -0.5322,  0.0976, -0.3454, -0.8688, -0.7892,\n",
              "           0.6425, -0.0715,  0.9421,  0.7474,  0.5856, -0.2838,  0.5736,  0.8443,\n",
              "          -0.6040, -0.2265, -0.5514, -0.4291,  0.1629, -0.7186, -0.9606,  0.4373,\n",
              "           0.7778,  0.9319,  0.4361,  0.6424, -0.4906, -0.0037,  0.2804,  0.5839,\n",
              "           0.3474, -0.9619, -0.2229,  0.0785, -0.9723,  0.9182,  0.0640, -0.3942,\n",
              "           0.1430, -0.2042, -0.0169, -0.2917, -0.9819,  0.2123, -0.1970, -0.9089,\n",
              "           0.9891,  0.6388,  0.2586,  0.8221,  0.9740, -0.1172, -0.7596, -0.2430,\n",
              "          -0.9176, -0.1339, -0.9844,  0.9909, -0.9966,  0.4481, -0.0497, -0.9174,\n",
              "           0.5177, -0.9970,  0.8562,  0.9023, -0.0503,  0.1259, -0.9192,  0.2905,\n",
              "          -0.6035,  0.9798, -0.3864,  0.2381, -0.8487, -0.9500, -0.9068, -0.7444,\n",
              "          -0.8599,  0.9797, -0.8239, -0.5041, -0.7897,  0.0877,  0.0705, -0.9117,\n",
              "           0.3173, -0.9890,  0.9372,  0.4266,  0.6111,  0.3943, -0.1115, -0.2845,\n",
              "           0.8607,  0.0367, -0.3866,  0.0656, -0.8435,  0.0787, -0.8298,  0.2577,\n",
              "           0.4427,  0.1591,  0.5287, -0.6884,  0.7211,  0.6985,  0.5777,  0.3644,\n",
              "           0.1092,  0.8207,  0.9850,  0.9799,  0.9453,  0.4133,  0.4811, -0.0424,\n",
              "          -0.5725,  0.8857,  0.4909, -0.0143, -0.4437, -0.2643,  0.3756,  0.6279,\n",
              "           0.2081, -0.3845, -0.5603,  0.4393, -0.2455,  0.7026, -0.2765,  0.2220,\n",
              "          -0.9130,  0.5588, -0.4635,  0.8799,  0.5819, -0.5412, -0.3469, -0.9103,\n",
              "           0.5407,  0.5059,  0.1720,  0.1237, -0.5829, -0.0347,  0.9410, -0.0186,\n",
              "          -0.9976, -0.8865,  0.3744, -0.9896, -0.4779, -0.2492,  0.5234, -0.6409,\n",
              "          -0.9078, -0.1924,  0.5682, -0.9879,  0.6669,  0.0685,  0.9776,  0.5206,\n",
              "           0.3989, -0.8661, -0.8567, -0.6512,  0.9867, -0.8815,  0.8841, -0.9777,\n",
              "          -0.0694,  0.5884,  0.1461, -0.8232,  0.0846,  0.0114, -0.2839,  0.8034,\n",
              "           0.3070, -0.9945,  0.0840, -0.3534, -0.5643, -0.4644, -0.5767,  0.8588,\n",
              "           0.3590, -0.0854, -0.4087, -0.2015, -0.4446,  0.5809,  0.3436,  0.2942,\n",
              "          -0.6731, -0.4279, -0.9619,  0.0383, -0.1081,  0.0607,  0.7771, -0.0650,\n",
              "          -0.0356, -0.9137, -0.0055,  0.8886,  0.2997, -0.7110, -0.6382,  0.8176,\n",
              "           0.9816,  0.6141, -0.0069,  0.8431, -0.1927, -0.3729, -0.1111,  0.4238,\n",
              "           0.7672,  0.7184,  0.1008,  0.1388,  0.4552, -0.3218, -0.6550, -0.5007,\n",
              "          -0.5273,  0.8131, -0.2757, -0.9864,  0.5846,  0.4063, -0.9402, -0.1307,\n",
              "           0.5326, -0.6407,  0.8055,  0.9947,  0.4126,  0.5354, -0.1860, -0.3885,\n",
              "          -0.1079, -0.5918, -0.9700,  0.9461,  0.3205,  0.5256, -0.4608,  0.2529,\n",
              "           0.9622,  0.6217, -0.3511, -0.4733,  0.2403, -0.1477, -0.9408,  0.8746,\n",
              "          -0.9903, -0.1325, -0.9425, -0.3779,  0.5365,  0.8895,  0.2612,  0.9375,\n",
              "           0.9497, -0.7520,  0.9735,  0.9107, -0.5896, -0.9685, -0.9808, -0.9037,\n",
              "          -0.7850,  0.2021, -0.7522,  0.7151, -0.1862, -0.6591, -0.2312, -0.1900,\n",
              "           0.8080,  0.1589, -0.8655,  0.9689,  0.1508, -0.8049,  0.5811, -0.9930,\n",
              "          -0.9056,  0.1106,  0.0075,  0.5245, -0.7098,  0.9691,  0.1486, -0.0148,\n",
              "          -0.6482,  0.7375, -0.9898, -0.8893,  0.5745,  0.8654, -0.7432,  0.9733,\n",
              "          -0.8189,  0.2740,  0.8865,  0.2413,  0.5710,  0.5056, -0.2893, -0.4843,\n",
              "           0.7339,  0.6759,  0.8010,  0.8836,  0.8291, -0.3986,  0.9564, -0.0691,\n",
              "           0.9880, -0.9734, -0.4166,  0.7420, -0.4612, -0.1601,  0.0043, -0.8368,\n",
              "           0.3838,  0.5687,  0.7586,  0.1462,  0.3340,  0.3970,  0.5892,  0.0107,\n",
              "          -0.3000,  0.0547,  0.4464,  0.9906,  0.6816, -0.1262,  0.7800,  0.2885,\n",
              "           0.6382, -0.5812,  0.4866, -0.4239,  0.1953,  0.3725, -0.3428,  0.9797,\n",
              "          -0.9098,  0.2932, -0.4607, -0.3519, -0.5382, -0.8344, -0.4437, -0.3525,\n",
              "           0.0907,  0.3019,  0.7013,  0.7060,  0.9591, -0.3640, -0.5760,  0.5018,\n",
              "           0.3969, -0.4441, -0.7112,  0.7229, -0.7255,  0.9638, -0.7761,  0.9556,\n",
              "          -0.9768,  0.5049,  0.9448, -0.7767,  0.2315,  0.6336, -0.7288,  0.9751,\n",
              "          -0.8467,  0.8856, -0.7716,  0.5763, -0.5588, -0.4134, -0.6316,  0.9730]],\n",
              "        grad_fn=<TanhBackward>)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy9VIIV4xg74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "87db1b4d-83ba-4b50-c3d1-0de4c454b9c8"
      },
      "source": [
        "import pickle\n",
        "# import importlib\n",
        "# importlib.reload(examples.encode_texts)\n",
        "\n",
        "def dump_embedding(typ):\n",
        "  root_path='/content/drive/My Drive/rumoureval-data/'\n",
        "  for e in ['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']:\n",
        "    # event_list=[]\n",
        "    ev=Event(root_path+e)\n",
        "    ev.create_tree(gb)\n",
        "    with open('/content/drive/My Drive/Tree_LSTM/data_{}_{}.pkl'.format(typ,e),'wb') as f:\n",
        "      pickle.dump(ev,f)\n",
        "\n",
        "# embedding=SKP(encoder)\n",
        "# embedding=DeepMoji()\n",
        "embedding=BERT()\n",
        "gb=Global()\n",
        "# dump_embedding('skp')\n",
        "dump_embedding('bert')      "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
            "  category=FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T44TQyY2D_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "17553a69-390b-4431-adc7-16e4902b722e"
      },
      "source": [
        "# with open('/content/drive/My Drive/data.pkl','rb') as f:\n",
        "#   event_list=pickle.load(f)\n",
        "for node in gb.g_nodes:\n",
        "  if(node.children is not None):\n",
        "    for child in node.children:\n",
        "      print('parent:{}; child{}'.format(node.id,child.id))\n",
        "  print(node.id)    \n",
        "# [node.id for node in gb.g_nodes]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "553184702530453505\n",
            "553184777315287040\n",
            "553184841873633280\n",
            "553184912258654208\n",
            "553185239791857664\n",
            "553185273639895040\n",
            "553185403650322432\n",
            "553185449150541824\n",
            "553186074311528448\n",
            "553187655434108928\n",
            "553199414659907584\n",
            "parent:553199295588212736; child553199414659907584\n",
            "553199295588212736\n",
            "parent:553197339813220352; child553199295588212736\n",
            "553197339813220352\n",
            "parent:553187777689694208; child553197339813220352\n",
            "553187777689694208\n",
            "553187813668425728\n",
            "553198944998543360\n",
            "parent:553197749240221699; child553198944998543360\n",
            "553197749240221699\n",
            "553549691129192448\n",
            "parent:553549483984711681; child553549691129192448\n",
            "553549483984711681\n",
            "parent:553498348674875393; child553549483984711681\n",
            "553498348674875393\n",
            "parent:553188394113986561; child553197749240221699\n",
            "parent:553188394113986561; child553498348674875393\n",
            "553188394113986561\n",
            "553188436178264066\n",
            "553200322231808001\n",
            "parent:553189048052105216; child553200322231808001\n",
            "553189048052105216\n",
            "553192939888058369\n",
            "553195335661912064\n",
            "553195879692517376\n",
            "553196247319064576\n",
            "parent:553184482241814530; child553184702530453505\n",
            "parent:553184482241814530; child553184777315287040\n",
            "parent:553184482241814530; child553184841873633280\n",
            "parent:553184482241814530; child553184912258654208\n",
            "parent:553184482241814530; child553185239791857664\n",
            "parent:553184482241814530; child553185273639895040\n",
            "parent:553184482241814530; child553185403650322432\n",
            "parent:553184482241814530; child553185449150541824\n",
            "parent:553184482241814530; child553186074311528448\n",
            "parent:553184482241814530; child553187655434108928\n",
            "parent:553184482241814530; child553187777689694208\n",
            "parent:553184482241814530; child553187813668425728\n",
            "parent:553184482241814530; child553188394113986561\n",
            "parent:553184482241814530; child553188436178264066\n",
            "parent:553184482241814530; child553189048052105216\n",
            "parent:553184482241814530; child553192939888058369\n",
            "parent:553184482241814530; child553195335661912064\n",
            "parent:553184482241814530; child553195879692517376\n",
            "parent:553184482241814530; child553196247319064576\n",
            "553184482241814530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqWWZHbLu4Pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3eeb82e0-92a5-4131-f053-7ae295791140"
      },
      "source": [
        "# Balancing each class for rumour labels\n",
        "def balance_embedding(typ):\n",
        "  ev_label_count=[]\n",
        "  for e in ['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']:\n",
        "    with open('/content/drive/My Drive/DeepMoji/data_{}_{}.pkl'.format(typ,e),'rb') as f:\n",
        "      ev=pickle.load(f)\n",
        "    label={0:0,1:0,2:0}   \n",
        "    # for event in ev:\n",
        "    for tree in ev.treelist:\n",
        "      label[veracity_dict[str(tree[0])]]+=1\n",
        "    ev_label_count.append((e,label))    \n",
        "  print(ev_label_count)\n",
        "  for e in ['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']:\n",
        "    with open('/content/drive/My Drive/DeepMoji/data_{}_{}.pkl'.format(typ,e),'rb') as f:\n",
        "      ev=pickle.load(f) \n",
        "    # for event in ev:\n",
        "    lbl_0_list=[]\n",
        "    lbl_1_list=[]\n",
        "    lbl_2_list=[]\n",
        "    for tree in ev.treelist: \n",
        "      if(veracity_dict[str(tree[0])]==0):\n",
        "        lbl_0_list.append(tree)      \n",
        "      elif(veracity_dict[str(tree[0])]==1):\n",
        "        lbl_1_list.append(tree)\n",
        "      elif(veracity_dict[str(tree[0])]==2):\n",
        "        lbl_2_list.append(tree)\n",
        "    if(e=='charliehebdo'):\n",
        "      for i in range(27):\n",
        "        ev.treelist.append(random.sample(lbl_1_list,1)[0])\n",
        "      for i in range(16):\n",
        "        ev.treelist.append(random.sample(lbl_2_list,1)[0])\n",
        "    elif(e=='sydneysiege'):\n",
        "      for i in range(38):\n",
        "        ev.treelist.append(random.sample(lbl_1_list,1)[0])\n",
        "      for i in range(44):\n",
        "        ev.treelist.append(random.sample(lbl_2_list,1)[0])   \n",
        "    elif(e=='germanwings-crash'):\n",
        "      for i in range(9):\n",
        "        ev.treelist.append(random.sample(lbl_2_list,1)[0]) \n",
        "    elif(e=='ferguson'):\n",
        "      for i in range(42):\n",
        "        ev.treelist.append(random.sample(lbl_0_list,1)[0])\n",
        "    elif(e=='ottawashooting'):\n",
        "      for i in range(40):\n",
        "        ev.treelist.append(random.sample(lbl_1_list,1)[0])    \n",
        "      for i in range(23):\n",
        "        ev.treelist.append(random.sample(lbl_2_list,1)[0])    \n",
        "    with open('/content/drive/My Drive/DeepMoji/data_{}_{}_balanced.pkl'.format(typ,e),'wb') as f:\n",
        "      pickle.dump(ev,f) \n",
        "\n",
        "  ev_label_count=[]\n",
        "  for e in ['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']:\n",
        "    with open('/content/drive/My Drive/DeepMoji/data_{}_{}_balanced.pkl'.format(typ,e),'rb') as f:\n",
        "      ev=pickle.load(f)\n",
        "    label={0:0,1:0,2:0}   \n",
        "    # for event in ev:\n",
        "    for tree in ev.treelist:\n",
        "      label[veracity_dict[str(tree[0])]]+=1\n",
        "    ev_label_count.append((e,label))    \n",
        "  print(ev_label_count) \n",
        "\n",
        "# balance_embedding('skp')                                                                   \n",
        "# balance_embedding('deepmoji')\n",
        "balance_embedding('bert')                                                                   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('charliehebdo', {0: 39, 1: 12, 2: 23}), ('sydneysiege', {0: 51, 1: 13, 2: 7}), ('germanwings-crash', {0: 10, 1: 12, 2: 3}), ('ferguson', {0: 2, 1: 0, 2: 44}), ('ottawashooting', {0: 35, 1: 10, 2: 13})]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('charliehebdo', {0: 39, 1: 39, 2: 39}), ('sydneysiege', {0: 51, 1: 51, 2: 51}), ('germanwings-crash', {0: 10, 1: 12, 2: 12}), ('ferguson', {0: 44, 1: 0, 2: 44}), ('ottawashooting', {0: 35, 1: 50, 2: 36})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8DIn9YRb7wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event_labels=['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']\n",
        "# change type for embedding skp,deepmoji,bert,mix(deepmoji+skp)\n",
        "def train_loader(val_index):\n",
        "  for e in [l for i,l in enumerate(event_labels) if i!=val_index]:\n",
        "    with open('/content/drive/My Drive/Tree_LSTM/data_bert_{}.pkl'.format(e),'rb') as f:\n",
        "      ev=pickle.load(f)\n",
        "    yield ev,e\n",
        "\n",
        "def val_loader(val_index):\n",
        "  for e in [l for i,l in enumerate(event_labels) if i==val_index]:\n",
        "    with open('/content/drive/My Drive/Tree_LSTM/data_bert_{}.pkl'.format(e),'rb') as f:\n",
        "      ev=pickle.load(f)\n",
        "    yield ev,e"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYHYx66fEFpq",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a33LzQVD-Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb17d8c3-902a-4bf6-e84e-db4b7e223774"
      },
      "source": [
        "# skp:\n",
        "# model=TreeLSTMCell(2400,2400)\n",
        "# deepmoji\n",
        "model=TreeLSTMCell(768,768)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=.008)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for e in range(30):\n",
        "  val_index=e%5\n",
        "  train_loss=0\n",
        "  for event,lbl in train_loader(val_index):\n",
        "    print('training on {}...'.format(lbl))\n",
        "    for tree in event.treelist:\n",
        "        loss=0\n",
        "        optimizer.zero_grad()\n",
        "        nodes=tree[1]\n",
        "        for i in range(len(nodes)):\n",
        "          nodes[i].h=None\n",
        "          nodes[i].c=None\n",
        "        model.reset_h_c()  \n",
        "        for i in range(len(nodes)):\n",
        "          if(i!=(len(nodes)-1)):\n",
        "            result=model(nodes[i])\n",
        "            if(result is not None and nodes[i].y is not None):\n",
        "              loss+=criterion(result,torch.tensor(nodes[i].y).view(-1))\n",
        "          else:\n",
        "            result=model(nodes[i],is_last=True)  \n",
        "            print(result,veracity_dict[str(tree[0])],node.id,node.children)        \n",
        "            loss+=criterion(result,torch.tensor(veracity_dict[str(tree[0])],dtype=torch.long).view(-1))            \n",
        "        train_loss+=loss.data.item()        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  print('train loss : {}'.format(train_loss))     \n",
        "  with torch.no_grad():\n",
        "    loss=0\n",
        "    for event,lbl in val_loader(val_index):\n",
        "      print('testing on {}...'.format(lbl))\n",
        "      for tree in event.treelist:\n",
        "        nodes=tree[1]\n",
        "        for i in range(len(nodes)):\n",
        "          nodes[i].h=None\n",
        "          nodes[i].c=None\n",
        "        model.reset_h_c()  \n",
        "        for i in range(len(nodes)):\n",
        "          if(i!=(len(nodes)-1)):\n",
        "            result=model(nodes[i])\n",
        "            if(result is not None and nodes[i].y is not None):\n",
        "              loss+=criterion(result,torch.tensor(nodes[i].y).view(-1)).data.item()\n",
        "          else:\n",
        "            result=model(nodes[i],is_last=True)\n",
        "            loss+=criterion(result,torch.tensor(veracity_dict[str(tree[0])],dtype=torch.long).view(-1)).data.item() \n",
        "    print('test loss : {}'.format(loss))\n",
        "    torch.save(model.state_dict(), '/content/drive/My Drive/model_bert.pt')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on sydneysiege...\n",
            "veracity:tensor([[0.2907, 0.3749, 0.3344]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.2907, 0.3749, 0.3344]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "veracity:tensor([[9.9999e-01, 3.1789e-06, 3.4650e-06]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[9.9999e-01, 3.1789e-06, 3.4650e-06]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.4017e-07, 1.4325e-07]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.4017e-07, 1.4325e-07]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3065e-08, 1.2197e-08]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3065e-08, 1.2197e-08]], grad_fn=<SoftmaxBackward>) 2 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3644e-09, 1.3086e-09]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3644e-09, 1.3086e-09]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 3.7240e-10, 3.3726e-10]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 3.7240e-10, 3.3726e-10]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3519e-10, 1.1721e-10]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3519e-10, 1.1721e-10]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.7644e-11, 1.6323e-11]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.7644e-11, 1.6323e-11]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 3.6768e-12, 3.4689e-12]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 3.6768e-12, 3.4689e-12]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 4.1101e-12, 3.6259e-12]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 4.1101e-12, 3.6259e-12]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 4.1052e-13, 4.1510e-13]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 4.1052e-13, 4.1510e-13]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.9907e-13, 1.9640e-13]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.9907e-13, 1.9640e-13]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.4122e-13, 1.3111e-13]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.4122e-13, 1.3111e-13]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 4.0217e-14, 4.1100e-14]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 4.0217e-14, 4.1100e-14]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 3.7384e-14, 3.4917e-14]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 3.7384e-14, 3.4917e-14]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.1359e-14, 2.0254e-14]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.1359e-14, 2.0254e-14]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.0557e-14, 1.8165e-14]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.0557e-14, 1.8165e-14]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 4.3025e-15, 4.3876e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 4.3025e-15, 4.3876e-15]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.2839e-15, 2.4695e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.2839e-15, 2.4695e-15]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 7.0203e-15, 6.0636e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 7.0203e-15, 6.0636e-15]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 5.4854e-15, 5.0970e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 5.4854e-15, 5.0970e-15]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 9.6587e-16, 1.0363e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 9.6587e-16, 1.0363e-15]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3798e-15, 1.2614e-15]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3798e-15, 1.2614e-15]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 8.4399e-16, 8.1721e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 8.4399e-16, 8.1721e-16]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.0512e-15, 9.5677e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.0512e-15, 9.5677e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 7.1956e-16, 6.6815e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 7.1956e-16, 6.6815e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 3.7076e-16, 3.6483e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 3.7076e-16, 3.6483e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.1900e-16, 2.1839e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.1900e-16, 2.1839e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.3614e-16, 2.3767e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.3614e-16, 2.3767e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 4.6304e-16, 4.1906e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 4.6304e-16, 4.1906e-16]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.0058e-16, 1.9579e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.0058e-16, 1.9579e-16]], grad_fn=<SoftmaxBackward>) 2 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.0813e-16, 2.0045e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.0813e-16, 2.0045e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 9.5836e-17, 9.7578e-17]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 9.5836e-17, 9.7578e-17]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.1777e-16, 1.2086e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.1777e-16, 1.2086e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.9550e-16, 2.5799e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.9550e-16, 2.5799e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.6338e-16, 1.5178e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.6338e-16, 1.5178e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3381e-16, 1.2764e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3381e-16, 1.2764e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 2.6555e-16, 2.4643e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 2.6555e-16, 2.4643e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.5689e-16, 1.4432e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.5689e-16, 1.4432e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3210e-16, 1.2686e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3210e-16, 1.2686e-16]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 5.3114e-17, 5.7833e-17]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 5.3114e-17, 5.7833e-17]], grad_fn=<SoftmaxBackward>) 1 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3559e-16, 1.2621e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3559e-16, 1.2621e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "veracity:tensor([[1.0000e+00, 1.3451e-16, 1.2577e-16]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[1.0000e+00, 1.3451e-16, 1.2577e-16]], grad_fn=<SoftmaxBackward>) 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n",
            "None 0 553184482241814530 [<__main__.Node object at 0x7f32c645d048>, <__main__.Node object at 0x7f32c70cf5c0>, <__main__.Node object at 0x7f32c70cf940>, <__main__.Node object at 0x7f32c70cf7b8>, <__main__.Node object at 0x7f32c70cf5f8>, <__main__.Node object at 0x7f32c70cf6d8>, <__main__.Node object at 0x7f32c70cf898>, <__main__.Node object at 0x7f32c70cf668>, <__main__.Node object at 0x7f32c70cf978>, <__main__.Node object at 0x7f32c70cf908>, <__main__.Node object at 0x7f32c70cf588>, <__main__.Node object at 0x7f32c70cf828>, <__main__.Node object at 0x7f32ca43e7f0>, <__main__.Node object at 0x7f32ca43edd8>, <__main__.Node object at 0x7f32ca43efd0>, <__main__.Node object at 0x7f32ca43eb70>, <__main__.Node object at 0x7f32ca43e358>, <__main__.Node object at 0x7f32ca43ecf8>, <__main__.Node object at 0x7f32ca43e320>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-c6f28531fbbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mveracity_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mveracity_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 932\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'log_softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdL7dbYYEJ_D",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63-8Mk1qwni4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "8ef448b0-4780-46e4-881a-f041721db40b"
      },
      "source": [
        "def val_loader(val_index):\n",
        "  for e in [l for i,l in enumerate(event_labels) if i==val_index]:\n",
        "    with open('/content/drive/My Drive/DeepMoji/data_bert_{}.pkl'.format(e),'rb') as f:\n",
        "      ev=pickle.load(f)\n",
        "    yield ev,e\n",
        "\n",
        "model=TreeLSTMCell(768,768)\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/model_bert.pt'))\n",
        "results={}\n",
        "for val_index in range(5):\n",
        "  with torch.no_grad():\n",
        "    for event,lbl in val_loader(val_index):\n",
        "      pred=[]\n",
        "      print('testing on {}...'.format(lbl))\n",
        "      for tree in event.treelist:\n",
        "        nodes=tree[1]\n",
        "        for i in range(len(nodes)):\n",
        "          nodes[i].h=None\n",
        "          nodes[i].c=None\n",
        "        model.reset_h_c()  \n",
        "        for i in range(len(nodes)):\n",
        "          # if(nodes[i].x is not None):\n",
        "            # print(nodes[i].x.tolist()[0][0],nodes[i].id)\n",
        "          if(i!=(len(nodes)-1)):\n",
        "            result=model(nodes[i])\n",
        "            \n",
        "          else:\n",
        "            result=model(nodes[i],is_last=True)\n",
        "            # print(result)\n",
        "            pred.append((torch.argmax(result).item(),veracity_dict[str(tree[0])]))\n",
        "      results[lbl]=pred        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing on charliehebdo...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a4b47219f164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# print(nodes[i].x.tolist()[0][0],nodes[i].id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Ep7ENKjd-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "04b51be6-723a-41b4-d56b-5de2a32375b2"
      },
      "source": [
        "ev_label_count=[]\n",
        "for e in ['charliehebdo','sydneysiege','germanwings-crash','ferguson','ottawashooting']:\n",
        "  with open('/content/drive/My Drive/DeepMoji/data_bert_{}.pkl'.format(e),'rb') as f:\n",
        "    ev=pickle.load(f)\n",
        "  label={0:0,1:0,2:0,3:0}   \n",
        "  # for event in ev:\n",
        "  for tree in ev.treelist:\n",
        "    nodes=tree[1]\n",
        "    for node in nodes:\n",
        "      if(node.y is not None):\n",
        "        label[node.y]+=1\n",
        "  ev_label_count.append((e,label))    \n",
        "print(ev_label_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('charliehebdo', {0: 169, 1: 719, 2: 53, 3: 56}), ('sydneysiege', {0: 150, 1: 700, 2: 98, 3: 88}), ('germanwings-crash', {0: 46, 1: 172, 2: 28, 3: 10}), ('ferguson', {0: 138, 1: 713, 2: 99, 3: 90}), ('ottawashooting', {0: 105, 1: 477, 2: 63, 3: 74})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_F-kbWvms1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}